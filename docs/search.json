[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "Analysis of Cars\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is Project 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nAman Sharma\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nAman Sharma\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project4/hw2_questions.html",
    "href": "blog/project4/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr)\n\nblueprinty &lt;- read_csv(\"/Users/amansharma/amn_website/amn_website/blog/project4/blueprinty.csv\")\n\nRows: 1500 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): region\ndbl (3): patents, age, iscustomer\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(blueprinty)\n\nRows: 1,500\nColumns: 4\n$ patents    &lt;dbl&gt; 0, 3, 4, 3, 3, 6, 5, 5, 6, 4, 2, 3, 7, 4, 5, 4, 2, 2, 2, 5,…\n$ region     &lt;chr&gt; \"Midwest\", \"Southwest\", \"Northwest\", \"Northeast\", \"Southwes…\n$ age        &lt;dbl&gt; 32.5, 37.5, 27.0, 24.5, 37.0, 29.5, 27.0, 20.5, 25.0, 29.5,…\n$ iscustomer &lt;dbl&gt; 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,…\n\n\n\n# Histogram: patents by customer status\nggplot(blueprinty, aes(x = patents, fill = factor(iscustomer))) +\n  geom_histogram(binwidth = 1, position = \"dodge\", color = \"white\") +\n  scale_fill_manual(values = c(\"#1b9e77\", \"#d95f02\"), labels = c(\"Non-customer\", \"Customer\")) +\n  labs(\n    title = \"Patent Counts by Customer Status\",\n    x = \"Number of Patents (Last 5 Years)\",\n    y = \"Number of Firms\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nOn average, Blueprinty no-customers hold more patents than the customers. The histogram shows this pattern visually, while the summary statistics confirm that the mean patent count is higher among non customers.\nMost firms in both groups have between 1 and 6 patents, with the peak around 3–4 patents.\nThe green bars (non-customers) dominate in the lower patent count range (e.g., 0 to 2 patents).\nThe orange bars (customers) are relatively more concentrated in the mid to higher ranges (e.g., 4 to 9 patents).\nAt the extreme end (e.g., 10+ patents), both groups taper off, but Blueprinty customers are slightly more represented.\nThe distribution of customer firms is shifted right, indicating higher patent activity. This supports the marketing claim that customers may be more successful—but it also highlights the need to control for possible confounders like firm age or region before attributing this difference solely to software use.\n\n# Boxplot of firm age\nggplot(blueprinty, aes(x = factor(iscustomer), y = age)) +\n  geom_boxplot(fill = \"#7570b3\") +\n  labs(\n    title = \"Firm Age by Customer Status\",\n    x = \"Customer Status (0 = No, 1 = Yes)\",\n    y = \"Firm Age (Years)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis boxplot compares the age of firms (in years since incorporation) between Blueprinty customers (1) and non-customers (0).\nWe can see that the median firm age is slightly higher among customers than non-customers. Both groups have similar spreads, with interquartile ranges (middle 50%) centered roughly between 20 and 35 years.\nThe overall distribution shows that customers tend to be just a bit older, though there’s substantial overlap. There is at least one mild outlier in the non-customer group (a firm around 49–50 years old).\nFirms using Blueprinty’s software tend to be slightly older on average than non-customers. This may indicate that more established or mature firms are more likely to adopt Blueprinty’s product. Since age may correlate with experience, resources, or patenting success, this is an important confounding variable to consider in any analysis that tries to isolate the effect of being a customer.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(-Inf)\n  sum(-lambda + Y * log(lambda) - lgamma(Y + 1))\n}\n\n\n# Poisson log-likelihood function\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(-Inf)  # enforce valid domain\n  ll &lt;- sum(dpois(Y, lambda, log = TRUE))\n  return(ll)\n}\n\n\n# Make sure your function is defined\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(-Inf)\n  sum(-lambda + Y * log(lambda) - lgamma(Y + 1))\n}\n\n# Use observed Y\nY &lt;- blueprinty$patents\n\n# Range of lambda values to try\nlambda_vals &lt;- seq(0.5, 10, by = 0.1)\n\n# Calculate log-likelihood for each lambda\nloglik_vals &lt;- sapply(lambda_vals, function(l) poisson_loglikelihood(l, Y))\n\n# Create data frame for plotting\nloglik_df &lt;- data.frame(lambda = lambda_vals, log_likelihood = loglik_vals)\n\n# Plot\nlibrary(ggplot2)\nggplot(loglik_df, aes(x = lambda, y = log_likelihood)) +\n  geom_line(color = \"#1b9e77\", linewidth = 1.2) +\n  labs(\n    title = \"Poisson Log-Likelihood for Lambda\",\n    x = expression(lambda),\n    y = \"Log-Likelihood\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\n\n# Negative log-likelihood for use with optim()\nneg_poisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(Inf)\n  -sum(dpois(Y, lambda, log = TRUE))  # or use manual formula\n}\n\n# Run optimization\nmle_result &lt;- optim(\n  par = 1,                      # initial guess\n  fn = neg_poisson_loglikelihood,\n  Y = blueprinty$patents,\n  method = \"Brent\",             # bounded method\n  lower = 0.001,\n  upper = 20\n)\n\n# View results\nmle_result$par      # MLE for lambda\n\n[1] 3.684667\n\nmle_result$value    # negative log-likelihood at MLE\n\n[1] 3367.684\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\npoisson_regression_loglikelihood &lt;- function(beta, Y, X) {\n  lambda &lt;- exp(X %*% beta)  # vector of lambda_i values\n  loglik &lt;- sum(Y * log(lambda) - lambda - lgamma(Y + 1))\n  return(-loglik)  # Negative for use with optim()\n}\n# Load model matrix\nblueprinty &lt;- blueprinty %&gt;%\n  mutate(age2 = age^2)  # add age squared manually\n\n# Outcome variable\nY &lt;- blueprinty$patents\n\n# Model matrix with intercept\nX &lt;- model.matrix(~ age + age2 + region + iscustomer, data = blueprinty)\n\n\n# Add age squared\nblueprinty &lt;- blueprinty %&gt;%\n  mutate(age2 = age^2)\n\n# Create model matrix X: includes intercept, age, age^2, region dummies, and iscustomer\nX &lt;- model.matrix(~ age + age2 + region + iscustomer, data = blueprinty)\n\n# Outcome vector\nY &lt;- blueprinty$patents\n\n\n# Negative log-likelihood function\npoisson_regression_loglikelihood &lt;- function(beta, Y, X) {\n  lambda &lt;- exp(X %*% beta)\n  -sum(Y * log(lambda) - lambda - lgamma(Y + 1))  # negative for minimization\n}\n\n# Initial values (0s)\nbeta_start &lt;- rep(0, ncol(X))\n\n# Estimate beta using optim\nmle_result &lt;- optim(\n  par = beta_start,\n  fn = poisson_regression_loglikelihood,\n  Y = Y,\n  X = X,\n  method = \"BFGS\",\n  hessian = TRUE\n)\n\n# Extract coefficients and variance-covariance matrix\nbeta_hat &lt;- mle_result$par\nvcov_mat &lt;- solve(mle_result$hessian)\nse_beta &lt;- sqrt(diag(vcov_mat))\n\n# Create coefficient table\nlibrary(tibble)\nlibrary(gt)\n\ncoef_table &lt;- tibble(\n  Term = colnames(X),\n  Estimate = beta_hat,\n  Std_Error = se_beta\n) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = c(Estimate, Std_Error), decimals = 4)\n\ncoef_table\n\n\n\n\n\n\n\nTerm\nEstimate\nStd_Error\n\n\n\n\n(Intercept)\n−0.1257\n0.1122\n\n\nage\n0.1158\n0.0064\n\n\nage2\n−0.0022\n0.0001\n\n\nregionNortheast\n−0.0246\n0.0434\n\n\nregionNorthwest\n−0.0348\n0.0529\n\n\nregionSouth\n−0.0054\n0.0524\n\n\nregionSouthwest\n−0.0378\n0.0472\n\n\niscustomer\n0.0607\n0.0321\n\n\n\n\n\n\nglm_model &lt;- glm(patents ~ age + I(age^2) + region + iscustomer,\n                 data = blueprinty, family = poisson())\n\nsummary(glm_model)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(), data = blueprinty)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.508920   0.183179  -2.778  0.00546 ** \nage              0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)        -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionNortheast  0.029170   0.043625   0.669  0.50372    \nregionNorthwest -0.017574   0.053781  -0.327  0.74383    \nregionSouth      0.056561   0.052662   1.074  0.28281    \nregionSouthwest  0.050576   0.047198   1.072  0.28391    \niscustomer       0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\nThe Poisson regression results suggest that firm age is a strong and significant predictor of patent output. Specifically, each additional year of age is associated with a 12% increase in expected patent counts, though this effect diminishes over time as indicated by the negative coefficient on age squared. Regional differences (compared to the Midwest baseline) do not appear to significantly affect patenting activity. Importantly, the coefficient on the iscustomer variable is positive and marginally significant, indicating that firms using Blueprinty’s software tend to have about 6% more patents on average, holding other factors constant. While this result is not strongly conclusive, it does lend modest support to Blueprinty’s marketing claim that its customers are more successful in obtaining patents.\n\n# Predicted lambda = exp(X %*% beta_hat)\n# Make two counterfactual datasets\nX_0 &lt;- X\nX_1 &lt;- X\n\n# Set all iscustomer values\nX_0[, \"iscustomer\"] &lt;- 0\nX_1[, \"iscustomer\"] &lt;- 1\n\n# Predicted lambda values\ny_pred_0 &lt;- exp(X_0 %*% beta_hat)\ny_pred_1 &lt;- exp(X_1 %*% beta_hat)\n\n# Estimate average treatment effect\nate &lt;- mean(y_pred_1 - y_pred_0)\nate\n\n[1] 0.2178843\n\n\nUsing the estimated Poisson regression model, we simulated expected patent counts for each firm under two scenarios: one where every firm is a Blueprinty customer and one where no firm is. On average, firms that use Blueprinty are predicted to have 0.22 more patents over the past five years than they would have had without the software, holding all else equal. While this is a modest difference, it represents a meaningful relative increase in expected patent output and provides evidence consistent with Blueprinty’s marketing claim that its customers are more successful in securing patents. However, because this is based on observational data, we cannot fully rule out the possibility that unobserved differences between customers and non-customers are influencing the result."
  },
  {
    "objectID": "blog/project4/hw2_questions.html#blueprinty-case-study",
    "href": "blog/project4/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr)\n\nblueprinty &lt;- read_csv(\"/Users/amansharma/amn_website/amn_website/blog/project4/blueprinty.csv\")\n\nRows: 1500 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): region\ndbl (3): patents, age, iscustomer\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(blueprinty)\n\nRows: 1,500\nColumns: 4\n$ patents    &lt;dbl&gt; 0, 3, 4, 3, 3, 6, 5, 5, 6, 4, 2, 3, 7, 4, 5, 4, 2, 2, 2, 5,…\n$ region     &lt;chr&gt; \"Midwest\", \"Southwest\", \"Northwest\", \"Northeast\", \"Southwes…\n$ age        &lt;dbl&gt; 32.5, 37.5, 27.0, 24.5, 37.0, 29.5, 27.0, 20.5, 25.0, 29.5,…\n$ iscustomer &lt;dbl&gt; 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,…\n\n\n\n# Histogram: patents by customer status\nggplot(blueprinty, aes(x = patents, fill = factor(iscustomer))) +\n  geom_histogram(binwidth = 1, position = \"dodge\", color = \"white\") +\n  scale_fill_manual(values = c(\"#1b9e77\", \"#d95f02\"), labels = c(\"Non-customer\", \"Customer\")) +\n  labs(\n    title = \"Patent Counts by Customer Status\",\n    x = \"Number of Patents (Last 5 Years)\",\n    y = \"Number of Firms\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nOn average, Blueprinty no-customers hold more patents than the customers. The histogram shows this pattern visually, while the summary statistics confirm that the mean patent count is higher among non customers.\nMost firms in both groups have between 1 and 6 patents, with the peak around 3–4 patents.\nThe green bars (non-customers) dominate in the lower patent count range (e.g., 0 to 2 patents).\nThe orange bars (customers) are relatively more concentrated in the mid to higher ranges (e.g., 4 to 9 patents).\nAt the extreme end (e.g., 10+ patents), both groups taper off, but Blueprinty customers are slightly more represented.\nThe distribution of customer firms is shifted right, indicating higher patent activity. This supports the marketing claim that customers may be more successful—but it also highlights the need to control for possible confounders like firm age or region before attributing this difference solely to software use.\n\n# Boxplot of firm age\nggplot(blueprinty, aes(x = factor(iscustomer), y = age)) +\n  geom_boxplot(fill = \"#7570b3\") +\n  labs(\n    title = \"Firm Age by Customer Status\",\n    x = \"Customer Status (0 = No, 1 = Yes)\",\n    y = \"Firm Age (Years)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis boxplot compares the age of firms (in years since incorporation) between Blueprinty customers (1) and non-customers (0).\nWe can see that the median firm age is slightly higher among customers than non-customers. Both groups have similar spreads, with interquartile ranges (middle 50%) centered roughly between 20 and 35 years.\nThe overall distribution shows that customers tend to be just a bit older, though there’s substantial overlap. There is at least one mild outlier in the non-customer group (a firm around 49–50 years old).\nFirms using Blueprinty’s software tend to be slightly older on average than non-customers. This may indicate that more established or mature firms are more likely to adopt Blueprinty’s product. Since age may correlate with experience, resources, or patenting success, this is an important confounding variable to consider in any analysis that tries to isolate the effect of being a customer.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(-Inf)\n  sum(-lambda + Y * log(lambda) - lgamma(Y + 1))\n}\n\n\n# Poisson log-likelihood function\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(-Inf)  # enforce valid domain\n  ll &lt;- sum(dpois(Y, lambda, log = TRUE))\n  return(ll)\n}\n\n\n# Make sure your function is defined\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(-Inf)\n  sum(-lambda + Y * log(lambda) - lgamma(Y + 1))\n}\n\n# Use observed Y\nY &lt;- blueprinty$patents\n\n# Range of lambda values to try\nlambda_vals &lt;- seq(0.5, 10, by = 0.1)\n\n# Calculate log-likelihood for each lambda\nloglik_vals &lt;- sapply(lambda_vals, function(l) poisson_loglikelihood(l, Y))\n\n# Create data frame for plotting\nloglik_df &lt;- data.frame(lambda = lambda_vals, log_likelihood = loglik_vals)\n\n# Plot\nlibrary(ggplot2)\nggplot(loglik_df, aes(x = lambda, y = log_likelihood)) +\n  geom_line(color = \"#1b9e77\", linewidth = 1.2) +\n  labs(\n    title = \"Poisson Log-Likelihood for Lambda\",\n    x = expression(lambda),\n    y = \"Log-Likelihood\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\n\n# Negative log-likelihood for use with optim()\nneg_poisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(Inf)\n  -sum(dpois(Y, lambda, log = TRUE))  # or use manual formula\n}\n\n# Run optimization\nmle_result &lt;- optim(\n  par = 1,                      # initial guess\n  fn = neg_poisson_loglikelihood,\n  Y = blueprinty$patents,\n  method = \"Brent\",             # bounded method\n  lower = 0.001,\n  upper = 20\n)\n\n# View results\nmle_result$par      # MLE for lambda\n\n[1] 3.684667\n\nmle_result$value    # negative log-likelihood at MLE\n\n[1] 3367.684\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\npoisson_regression_loglikelihood &lt;- function(beta, Y, X) {\n  lambda &lt;- exp(X %*% beta)  # vector of lambda_i values\n  loglik &lt;- sum(Y * log(lambda) - lambda - lgamma(Y + 1))\n  return(-loglik)  # Negative for use with optim()\n}\n# Load model matrix\nblueprinty &lt;- blueprinty %&gt;%\n  mutate(age2 = age^2)  # add age squared manually\n\n# Outcome variable\nY &lt;- blueprinty$patents\n\n# Model matrix with intercept\nX &lt;- model.matrix(~ age + age2 + region + iscustomer, data = blueprinty)\n\n\n# Add age squared\nblueprinty &lt;- blueprinty %&gt;%\n  mutate(age2 = age^2)\n\n# Create model matrix X: includes intercept, age, age^2, region dummies, and iscustomer\nX &lt;- model.matrix(~ age + age2 + region + iscustomer, data = blueprinty)\n\n# Outcome vector\nY &lt;- blueprinty$patents\n\n\n# Negative log-likelihood function\npoisson_regression_loglikelihood &lt;- function(beta, Y, X) {\n  lambda &lt;- exp(X %*% beta)\n  -sum(Y * log(lambda) - lambda - lgamma(Y + 1))  # negative for minimization\n}\n\n# Initial values (0s)\nbeta_start &lt;- rep(0, ncol(X))\n\n# Estimate beta using optim\nmle_result &lt;- optim(\n  par = beta_start,\n  fn = poisson_regression_loglikelihood,\n  Y = Y,\n  X = X,\n  method = \"BFGS\",\n  hessian = TRUE\n)\n\n# Extract coefficients and variance-covariance matrix\nbeta_hat &lt;- mle_result$par\nvcov_mat &lt;- solve(mle_result$hessian)\nse_beta &lt;- sqrt(diag(vcov_mat))\n\n# Create coefficient table\nlibrary(tibble)\nlibrary(gt)\n\ncoef_table &lt;- tibble(\n  Term = colnames(X),\n  Estimate = beta_hat,\n  Std_Error = se_beta\n) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = c(Estimate, Std_Error), decimals = 4)\n\ncoef_table\n\n\n\n\n\n\n\nTerm\nEstimate\nStd_Error\n\n\n\n\n(Intercept)\n−0.1257\n0.1122\n\n\nage\n0.1158\n0.0064\n\n\nage2\n−0.0022\n0.0001\n\n\nregionNortheast\n−0.0246\n0.0434\n\n\nregionNorthwest\n−0.0348\n0.0529\n\n\nregionSouth\n−0.0054\n0.0524\n\n\nregionSouthwest\n−0.0378\n0.0472\n\n\niscustomer\n0.0607\n0.0321\n\n\n\n\n\n\nglm_model &lt;- glm(patents ~ age + I(age^2) + region + iscustomer,\n                 data = blueprinty, family = poisson())\n\nsummary(glm_model)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(), data = blueprinty)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.508920   0.183179  -2.778  0.00546 ** \nage              0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)        -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionNortheast  0.029170   0.043625   0.669  0.50372    \nregionNorthwest -0.017574   0.053781  -0.327  0.74383    \nregionSouth      0.056561   0.052662   1.074  0.28281    \nregionSouthwest  0.050576   0.047198   1.072  0.28391    \niscustomer       0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\nThe Poisson regression results suggest that firm age is a strong and significant predictor of patent output. Specifically, each additional year of age is associated with a 12% increase in expected patent counts, though this effect diminishes over time as indicated by the negative coefficient on age squared. Regional differences (compared to the Midwest baseline) do not appear to significantly affect patenting activity. Importantly, the coefficient on the iscustomer variable is positive and marginally significant, indicating that firms using Blueprinty’s software tend to have about 6% more patents on average, holding other factors constant. While this result is not strongly conclusive, it does lend modest support to Blueprinty’s marketing claim that its customers are more successful in obtaining patents.\n\n# Predicted lambda = exp(X %*% beta_hat)\n# Make two counterfactual datasets\nX_0 &lt;- X\nX_1 &lt;- X\n\n# Set all iscustomer values\nX_0[, \"iscustomer\"] &lt;- 0\nX_1[, \"iscustomer\"] &lt;- 1\n\n# Predicted lambda values\ny_pred_0 &lt;- exp(X_0 %*% beta_hat)\ny_pred_1 &lt;- exp(X_1 %*% beta_hat)\n\n# Estimate average treatment effect\nate &lt;- mean(y_pred_1 - y_pred_0)\nate\n\n[1] 0.2178843\n\n\nUsing the estimated Poisson regression model, we simulated expected patent counts for each firm under two scenarios: one where every firm is a Blueprinty customer and one where no firm is. On average, firms that use Blueprinty are predicted to have 0.22 more patents over the past five years than they would have had without the software, holding all else equal. While this is a modest difference, it represents a meaningful relative increase in expected patent output and provides evidence consistent with Blueprinty’s marketing claim that its customers are more successful in securing patents. However, because this is based on observational data, we cannot fully rule out the possibility that unobserved differences between customers and non-customers are influencing the result."
  },
  {
    "objectID": "blog/project4/hw2_questions.html#airbnb-case-study",
    "href": "blog/project4/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n# Load packages\nlibrary(tidyverse)\nlibrary(readr)\n\n# Read data\nairbnb &lt;- read_csv(\"/Users/amansharma/amn_website/amn_website/blog/project4/airbnb.csv\")\n\nNew names:\nRows: 40628 Columns: 14\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(3): last_scraped, host_since, room_type dbl (10): ...1, id, days, bathrooms,\nbedrooms, price, number_of_reviews, rev... lgl (1): instant_bookable\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n# Glimpse structure\nglimpse(airbnb)\n\nRows: 40,628\nColumns: 14\n$ ...1                      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…\n$ id                        &lt;dbl&gt; 2515, 2595, 3647, 3831, 4611, 5099, 5107, 51…\n$ days                      &lt;dbl&gt; 3130, 3127, 3050, 3038, 3012, 2981, 2981, 29…\n$ last_scraped              &lt;chr&gt; \"4/2/2017\", \"4/2/2017\", \"4/2/2017\", \"4/2/201…\n$ host_since                &lt;chr&gt; \"9/6/2008\", \"9/9/2008\", \"11/25/2008\", \"12/7/…\n$ room_type                 &lt;chr&gt; \"Private room\", \"Entire home/apt\", \"Private …\n$ bathrooms                 &lt;dbl&gt; 1, 1, 1, 1, NA, 1, 1, NA, 1, 1, 1, 1, 1, NA,…\n$ bedrooms                  &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2,…\n$ price                     &lt;dbl&gt; 59, 230, 150, 89, 39, 212, 250, 60, 129, 79,…\n$ number_of_reviews         &lt;dbl&gt; 150, 20, 0, 116, 93, 60, 60, 50, 53, 329, 11…\n$ review_scores_cleanliness &lt;dbl&gt; 9, 9, NA, 9, 9, 9, 10, 8, 9, 7, 10, 9, 9, 9,…\n$ review_scores_location    &lt;dbl&gt; 9, 10, NA, 9, 8, 9, 9, 9, 10, 10, 10, 9, 10,…\n$ review_scores_value       &lt;dbl&gt; 9, 9, NA, 9, 9, 9, 10, 9, 9, 9, 10, 9, 10, 9…\n$ instant_bookable          &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FAL…\n\n# Remove rows with missing values in relevant columns\nairbnb_clean &lt;- airbnb %&gt;%\n  drop_na(number_of_reviews, price, room_type, bedrooms, bathrooms,\n          review_scores_cleanliness, review_scores_location, review_scores_value,\n          instant_bookable)\n\n# Confirm cleaned data\nsummary(airbnb_clean$number_of_reviews)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    3.00    8.00   21.17   26.00  421.00 \n\n\n\nggplot(airbnb_clean, aes(x = number_of_reviews)) +\n  geom_histogram(binwidth = 5, fill = \"#1f77b4\", color = \"white\") +\n  labs(title = \"Distribution of Number of Reviews (Bookings Proxy)\",\n       x = \"Number of Reviews\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis histogram shows the distribution of the number of reviews across Airbnb listings in New York City, which is used as a proxy for the number of bookings.\nThe distribution is heavily right-skewed, meaning the vast majority of listings have fewer than 50 reviews, with a large concentration around 0–10 reviews. A small number of listings have very high review counts (over 100 or even 200), but these are rare outliers.\nThis shape is typical of count data with many low values and a long tail — making a Poisson regression model a reasonable choice for analysis.\nThe shape of this distribution supports the use of Poisson or count-based regression methods, which assume non-negative integer outcomes and are particularly suited to modeling event counts like bookings or reviews. However, the presence of many zeros and high-variance may also suggest exploring overdispersion later, possibly with a negative binomial model if needed.\n\nggplot(airbnb_clean, aes(x = room_type, y = number_of_reviews)) +\n  geom_boxplot(fill = \"#2ca02c\") +\n  labs(title = \"Number of Reviews by Room Type\",\n       x = \"Room Type\",\n       y = \"Number of Reviews\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis boxplot shows the distribution of the number of reviews (used as a proxy for bookings) across three different room types on Airbnb:\n\nEntire home/apartment\nPrivate room\nShared room\n\nAll three room types have a similar median number of reviews, generally falling in the 10–25 review range. Private rooms appear to have a slightly higher concentration of listings with very high review counts, as seen from the extended upper whisker and more extreme outliers. Shared rooms tend to have a slightly lower distribution overall, though still with some high-performing listings. There is a long tail in all categories — some listings in each room type have well over 300 reviews, suggesting a few very frequently booked or long-standing listings.\nRoom type clearly plays a role in the distribution of reviews. While the medians are not dramatically different, the spread and number of high-review outliers vary across room types. This suggests that room type may have a nonlinear or interaction effect and should definitely be included as a predictor in any Poisson regression modeling of booking behavior.\n\n# Convert instant_bookable to binary\nairbnb_clean &lt;- airbnb_clean %&gt;%\n  mutate(instant_bookable = ifelse(instant_bookable == \"t\", 1, 0))\n\n# Fit Poisson regression\nmodel_airbnb &lt;- glm(\n  number_of_reviews ~ price + bedrooms + bathrooms + room_type +\n    review_scores_cleanliness + review_scores_location +\n    review_scores_value + instant_bookable,\n  data = airbnb_clean,\n  family = poisson()\n)\n\nsummary(model_airbnb)\n\n\nCall:\nglm(formula = number_of_reviews ~ price + bedrooms + bathrooms + \n    room_type + review_scores_cleanliness + review_scores_location + \n    review_scores_value + instant_bookable, family = poisson(), \n    data = airbnb_clean)\n\nCoefficients: (1 not defined because of singularities)\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                3.714e+00  1.587e-02 233.976  &lt; 2e-16 ***\nprice                     -3.275e-05  8.521e-06  -3.843 0.000121 ***\nbedrooms                   7.607e-02  2.001e-03  38.016  &lt; 2e-16 ***\nbathrooms                 -1.164e-01  3.786e-03 -30.751  &lt; 2e-16 ***\nroom_typePrivate room      7.405e-03  2.734e-03   2.709 0.006747 ** \nroom_typeShared room      -2.262e-01  8.616e-03 -26.249  &lt; 2e-16 ***\nreview_scores_cleanliness  1.140e-01  1.486e-03  76.750  &lt; 2e-16 ***\nreview_scores_location    -8.065e-02  1.599e-03 -50.445  &lt; 2e-16 ***\nreview_scores_value       -9.749e-02  1.789e-03 -54.484  &lt; 2e-16 ***\ninstant_bookable                  NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 961626  on 30159  degrees of freedom\nResidual deviance: 949198  on 30151  degrees of freedom\nAIC: 1070683\n\nNumber of Fisher Scoring iterations: 6\n\n\nThis model estimates the number of reviews (used as a proxy for bookings) based on Airbnb listing characteristics. Several variables are statistically significant:\n\nPrice has a small but significant negative effect: higher-priced listings tend to receive slightly fewer reviews, likely due to lower demand.\nBedrooms is positively associated with reviews: more bedrooms lead to more bookings, likely reflecting group travel.\nBathrooms surprisingly has a negative effect, which may indicate multicollinearity or that additional bathrooms don’t drive bookings once room size is accounted for.\nRoom Type: Listings categorized as Private rooms receive slightly more reviews than entire homes. Shared rooms receive significantly fewer reviews than entire homes.\nReview scores: Cleanliness has a strong positive association with bookings. Location and value have negative coefficients, possibly due to rating inflation (e.g., everyone gets 9s, so only lower scores stand out negatively).\n\nThe variable instant_bookable was dropped due to multicollinearity (likely perfectly predicted by other variables or has no variation in part of the data).\nListings with more bedrooms, higher cleanliness ratings, and those categorized as private rooms tend to receive more reviews. On the other hand, higher prices, shared rooms, and lower review scores for location and value are associated with fewer bookings. This model provides useful insights into what drives demand on Airbnb, with many predictors showing strong, statistically significant relationships."
  },
  {
    "objectID": "blog/project1/index.html#sub-header",
    "href": "blog/project1/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "Sub-Header",
    "text": "Sub-Header\nHere is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aman Sharma",
    "section": "",
    "text": "Here is a paragraph about me!\nAman is a graduate Business Analytics student at UC San Diego with a strong foundation in economics, data analytics, and strategic problem-solving. His diverse experience spans both public and private sectors, where he has worked in data management, market analysis, and operational strategy. Skilled in Excel, SQL, Python, and business intelligence tools like Tableau, he has applied these technical abilities in real-world projects and internships, refining his ability to translate complex data into actionable insights.\nWith a passion for business strategy and consulting, Aman has worked on projects with firms like UrbanCompany and various government institutions, where he gained firsthand experience in optimizing operations, scaling initiatives, and solving business challenges using data. As the founder of the only graduate-level consulting club at UC San Diego, he has led efforts to connect students with industry leaders, develop case-solving frameworks, and grow the club to 150+ members in just four months. His career goal is to leverage analytics, problem-solving, and cross-functional collaboration to help organizations navigate complex challenges and drive growth."
  },
  {
    "objectID": "blog/project3/index.html",
    "href": "blog/project3/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project3/index.html#introduction",
    "href": "blog/project3/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project3/index.html#data",
    "href": "blog/project3/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nlibrary(haven)\ndata &lt;- read_dta(\"/Users/amansharma/amn_website/amn_website/blog/project3/karlan_list_2007.dta\")\n\n\n\n\n\n\n\nDescription\n\n\n\n\n\n\n# Load packages\nlibrary(haven)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(skimr)\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(gt)  \n# Read and clean data\ndata &lt;- read_dta(\"karlan_list_2007.dta\") %&gt;%\n  clean_names()\n\n# Glimpse structure\nglimpse(data)\n\nRows: 50,083\nColumns: 51\n$ treatment          &lt;dbl&gt; 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, …\n$ control            &lt;dbl&gt; 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, …\n$ ratio              &lt;dbl+lbl&gt; 0, 0, 1, 1, 1, 0, 1, 2, 2, 1, 1, 2, 0, 2, 0, 1,…\n$ ratio2             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, …\n$ ratio3             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …\n$ size               &lt;dbl+lbl&gt; 0, 0, 3, 4, 2, 0, 1, 3, 4, 1, 4, 2, 0, 1, 0, 4,…\n$ size25             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, …\n$ size50             &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n$ size100            &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ sizeno             &lt;dbl&gt; 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, …\n$ ask                &lt;dbl+lbl&gt; 0, 0, 1, 1, 1, 0, 3, 3, 2, 2, 1, 3, 0, 2, 0, 1,…\n$ askd1              &lt;dbl&gt; 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, …\n$ askd2              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, …\n$ askd3              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n$ ask1               &lt;dbl&gt; 55, 25, 55, 55, 35, 95, 125, 75, 250, 150, 125, 25,…\n$ ask2               &lt;dbl&gt; 70, 35, 70, 70, 45, 120, 160, 95, 315, 190, 160, 35…\n$ ask3               &lt;dbl&gt; 85, 50, 85, 85, 55, 145, 190, 120, 375, 225, 190, 5…\n$ amount             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ gave               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ amountchange       &lt;dbl&gt; -45, -25, -50, -25, -15, -45, -50, -65, -100, -125,…\n$ hpa                &lt;dbl&gt; 45, 25, 50, 50, 25, 90, 100, 65, 200, 125, 100, 5, …\n$ ltmedmra           &lt;dbl&gt; 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, …\n$ freq               &lt;dbl&gt; 2, 2, 3, 15, 42, 20, 12, 13, 28, 4, 1, 1, 2, 80, 3,…\n$ years              &lt;dbl&gt; 4, 3, 2, 8, 95, 10, 8, 16, 19, 7, 3, 1, 6, 19, 3, 1…\n$ year5              &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, …\n$ mrm2               &lt;dbl&gt; 31, 5, 6, 1, 24, 3, 4, 4, 6, 35, 41, 8, 28, 15, 5, …\n$ dormant            &lt;dbl&gt; 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, …\n$ female             &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ couple             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ state50one         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ nonlit             &lt;dbl&gt; 5, 0, 3, 1, 1, 0, 0, 4, 1, 4, 4, 1, 1, 4, 0, 3, 6, …\n$ cases              &lt;dbl&gt; 4, 2, 1, 2, 1, 0, 1, 3, 1, 3, 3, 2, 1, 1, 1, 1, 2, …\n$ statecnt           &lt;dbl&gt; 4.5002995, 2.9822462, 9.6070213, 3.2814682, 2.30201…\n$ stateresponse      &lt;dbl&gt; 0.01994681, 0.02608696, 0.02304817, 0.02066869, 0.0…\n$ stateresponset     &lt;dbl&gt; 0.019502353, 0.027833002, 0.022158911, 0.024702653,…\n$ stateresponsec     &lt;dbl&gt; 0.020806242, 0.022494888, 0.024743512, 0.012681159,…\n$ stateresponsetminc &lt;dbl&gt; -0.001303889, 0.005338114, -0.002584601, 0.01202149…\n$ perbush            &lt;dbl&gt; 0.4900000, 0.4646465, 0.4081633, 0.4646465, 0.52525…\n$ close25            &lt;dbl&gt; 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, …\n$ red0               &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, …\n$ blue0              &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, …\n$ redcty             &lt;dbl&gt; 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, …\n$ bluecty            &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, …\n$ pwhite             &lt;dbl&gt; 0.4464934, NA, 0.9357064, 0.8883309, 0.7590141, 0.8…\n$ pblack             &lt;dbl&gt; 0.527769208, NA, 0.011948366, 0.010760401, 0.127420…\n$ page18_39          &lt;dbl&gt; 0.3175913, NA, 0.2761282, 0.2794118, 0.4423889, 0.3…\n$ ave_hh_sz          &lt;dbl&gt; 2.10, NA, 2.48, 2.65, 1.85, 2.92, 2.10, 2.47, 2.49,…\n$ median_hhincome    &lt;dbl&gt; 28517, NA, 51175, 79269, 40908, 61779, 54655, 14152…\n$ powner             &lt;dbl&gt; 0.4998072, NA, 0.7219406, 0.9204314, 0.4160721, 0.9…\n$ psch_atlstba       &lt;dbl&gt; 0.32452780, NA, 0.19266793, 0.41214216, 0.43996516,…\n$ pop_propurban      &lt;dbl&gt; 1.0000000, NA, 1.0000000, 1.0000000, 1.0000000, 0.9…\n\n# Skim summary\nskim(data)\n\n\nData summary\n\n\nName\ndata\n\n\nNumber of rows\n50083\n\n\nNumber of columns\n51\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n51\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ntreatment\n0\n1.00\n0.67\n0.47\n0.00\n0.00\n1.00\n1.00\n1.00\n▃▁▁▁▇\n\n\ncontrol\n0\n1.00\n0.33\n0.47\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▃\n\n\nratio\n0\n1.00\n1.33\n1.15\n0.00\n0.00\n1.00\n2.00\n3.00\n▇▆▁▆▆\n\n\nratio2\n0\n1.00\n0.22\n0.42\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\nratio3\n0\n1.00\n0.22\n0.42\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\nsize\n0\n1.00\n1.67\n1.49\n0.00\n0.00\n2.00\n3.00\n4.00\n▇▅▅▅▅\n\n\nsize25\n0\n1.00\n0.17\n0.37\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\nsize50\n0\n1.00\n0.17\n0.37\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\nsize100\n0\n1.00\n0.17\n0.37\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\nsizeno\n0\n1.00\n0.17\n0.37\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\nask\n0\n1.00\n1.33\n1.15\n0.00\n0.00\n1.00\n2.00\n3.00\n▇▆▁▆▆\n\n\naskd1\n0\n1.00\n0.22\n0.42\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\naskd2\n0\n1.00\n0.22\n0.42\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\naskd3\n0\n1.00\n0.22\n0.42\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\nask1\n0\n1.00\n71.50\n101.73\n25.00\n35.00\n45.00\n65.00\n1500.00\n▇▁▁▁▁\n\n\nask2\n0\n1.00\n91.79\n127.25\n35.00\n45.00\n60.00\n85.00\n1875.00\n▇▁▁▁▁\n\n\nask3\n0\n1.00\n111.05\n151.67\n50.00\n55.00\n70.00\n100.00\n2250.00\n▇▁▁▁▁\n\n\namount\n0\n1.00\n0.92\n8.71\n0.00\n0.00\n0.00\n0.00\n400.00\n▇▁▁▁▁\n\n\ngave\n0\n1.00\n0.02\n0.14\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▁\n\n\namountchange\n0\n1.00\n-52.67\n1267.24\n-200412.12\n-50.00\n-30.00\n-25.00\n275.00\n▁▁▁▁▇\n\n\nhpa\n0\n1.00\n59.38\n71.18\n0.00\n30.00\n45.00\n60.00\n1000.00\n▇▁▁▁▁\n\n\nltmedmra\n0\n1.00\n0.49\n0.50\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▇\n\n\nfreq\n0\n1.00\n8.04\n11.39\n0.00\n2.00\n4.00\n10.00\n218.00\n▇▁▁▁▁\n\n\nyears\n1\n1.00\n6.10\n5.50\n0.00\n2.00\n5.00\n9.00\n95.00\n▇▁▁▁▁\n\n\nyear5\n0\n1.00\n0.51\n0.50\n0.00\n0.00\n1.00\n1.00\n1.00\n▇▁▁▁▇\n\n\nmrm2\n1\n1.00\n13.01\n12.08\n0.00\n4.00\n8.00\n19.00\n168.00\n▇▁▁▁▁\n\n\ndormant\n0\n1.00\n0.52\n0.50\n0.00\n0.00\n1.00\n1.00\n1.00\n▇▁▁▁▇\n\n\nfemale\n1111\n0.98\n0.28\n0.45\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▃\n\n\ncouple\n1148\n0.98\n0.09\n0.29\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▁\n\n\nstate50one\n0\n1.00\n0.00\n0.03\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▁\n\n\nnonlit\n452\n0.99\n2.47\n1.96\n0.00\n1.00\n3.00\n4.00\n6.00\n▇▁▂▅▃\n\n\ncases\n452\n0.99\n1.50\n1.16\n0.00\n1.00\n1.00\n2.00\n4.00\n▅▇▅▅▁\n\n\nstatecnt\n0\n1.00\n6.00\n5.75\n0.00\n1.83\n3.54\n9.61\n17.37\n▇▅▂▁▃\n\n\nstateresponse\n0\n1.00\n0.02\n0.01\n0.00\n0.02\n0.02\n0.02\n0.08\n▁▇▁▁▁\n\n\nstateresponset\n0\n1.00\n0.02\n0.01\n0.00\n0.02\n0.02\n0.02\n0.11\n▇▅▁▁▁\n\n\nstateresponsec\n3\n1.00\n0.02\n0.01\n0.00\n0.01\n0.02\n0.02\n0.05\n▁▇▂▁▁\n\n\nstateresponsetminc\n3\n1.00\n0.00\n0.01\n-0.05\n0.00\n0.00\n0.01\n0.11\n▁▇▁▁▁\n\n\nperbush\n35\n1.00\n0.49\n0.08\n0.09\n0.44\n0.48\n0.53\n0.73\n▁▁▇▇▂\n\n\nclose25\n35\n1.00\n0.19\n0.39\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\nred0\n35\n1.00\n0.40\n0.49\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▆\n\n\nblue0\n35\n1.00\n0.60\n0.49\n0.00\n0.00\n1.00\n1.00\n1.00\n▆▁▁▁▇\n\n\nredcty\n105\n1.00\n0.51\n0.50\n0.00\n0.00\n1.00\n1.00\n1.00\n▇▁▁▁▇\n\n\nbluecty\n105\n1.00\n0.49\n0.50\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▇\n\n\npwhite\n1866\n0.96\n0.82\n0.17\n0.01\n0.76\n0.87\n0.94\n1.00\n▁▁▁▂▇\n\n\npblack\n2036\n0.96\n0.09\n0.14\n0.00\n0.01\n0.04\n0.09\n0.99\n▇▁▁▁▁\n\n\npage18_39\n1866\n0.96\n0.32\n0.10\n0.00\n0.26\n0.31\n0.37\n1.00\n▁▇▂▁▁\n\n\nave_hh_sz\n1862\n0.96\n2.43\n0.38\n0.00\n2.21\n2.44\n2.66\n5.27\n▁▂▇▁▁\n\n\nmedian_hhincome\n1874\n0.96\n54815.70\n22027.32\n5000.00\n39181.00\n50673.00\n66005.00\n200001.00\n▆▇▁▁▁\n\n\npowner\n1869\n0.96\n0.67\n0.19\n0.00\n0.56\n0.71\n0.82\n1.00\n▁▂▃▇▆\n\n\npsch_atlstba\n1868\n0.96\n0.39\n0.19\n0.00\n0.24\n0.37\n0.53\n1.00\n▃▇▆▃▁\n\n\npop_propurban\n1866\n0.96\n0.87\n0.26\n0.00\n0.88\n1.00\n1.00\n1.00\n▁▁▁▁▇\n\n\n\n\n# Summary table (main dashboard)\nsummary_table &lt;- data %&gt;%\n  summarise(\n    `Total Observations` = n(),\n    `Treatment Share` = mean(treatment),\n    `Donation Rate` = mean(gave),\n    `Average Donation (all)` = mean(amount, na.rm = TRUE),\n    `Average Donation (if gave)` = mean(amount[gave == 1], na.rm = TRUE)\n  ) %&gt;%\n  gt() %&gt;%\n  fmt_percent(columns = c(2, 3), decimals = 1) %&gt;%\n  fmt_number(columns = 4:5, decimals = 2)\n\nsummary_table\n\n\n\n\n\n\n\nTotal Observations\nTreatment Share\nDonation Rate\nAverage Donation (all)\nAverage Donation (if gave)\n\n\n\n\n50083\n66.7%\n2.1%\n0.92\n44.35\n\n\n\n\n\n\n# Group-level summary\ndata %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(\n    response_rate = mean(gave),\n    avg_donation = mean(amount),\n    n = n()\n  )\n\n# A tibble: 2 × 4\n  treatment response_rate avg_donation     n\n      &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt; &lt;int&gt;\n1         0        0.0179        0.813 16687\n2         1        0.0220        0.967 33396\n\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nlibrary(dplyr)\nlibrary(broom)\n\n# Split data\ntreat &lt;- filter(data, treatment == 1)\ncontrol &lt;- filter(data, treatment == 0)\n\n\n# Variable 1: Months since last donation (mrm2)\nmean_diff_mrm2 &lt;- mean(treat$mrm2, na.rm = TRUE) - mean(control$mrm2, na.rm = TRUE)\nse_mrm2 &lt;- sqrt(var(treat$mrm2, na.rm = TRUE)/nrow(treat) +\n                var(control$mrm2, na.rm = TRUE)/nrow(control))\nt_stat_mrm2 &lt;- mean_diff_mrm2 / se_mrm2\n\n\n# Variable 2: Highest previous contribution (hpa)\nmean_diff_hpa &lt;- mean(treat$hpa, na.rm = TRUE) - mean(control$hpa, na.rm = TRUE)\nse_hpa &lt;- sqrt(var(treat$hpa, na.rm = TRUE)/nrow(treat) +\n               var(control$hpa, na.rm = TRUE)/nrow(control))\nt_stat_hpa &lt;- mean_diff_hpa / se_hpa\n\n\n# Display t-stats\nt_stat_mrm2\n\n[1] 0.1195321\n\nt_stat_hpa\n\n[1] 0.97043\n\n\n\n# Regress mrm2 (months since last donation) on treatment\nmodel_mrm2 &lt;- lm(mrm2 ~ treatment, data = data)\ntidy(model_mrm2)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  13.0       0.0935   139.      0    \n2 treatment     0.0137    0.115      0.119   0.905\n\n\n\n# Regress hpa (highest previous contribution) on treatment\nmodel_hpa &lt;- lm(hpa ~ treatment, data = data)\ntidy(model_hpa)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)   59.0       0.551   107.      0    \n2 treatment      0.637     0.675     0.944   0.345\n\n\n\n\n\n\n\n\nTable 1 in Karlan & List (2007) reports summary statistics by treatment and control to:\n\nShow that randomization succeeded — groups look balanced.\nBuild confidence that observed outcome differences are due to the treatment, not confounders.\n\nThis is standard in field experiments and pre-registered RCTs — a “sanity check” for the experiment’s internal validity."
  },
  {
    "objectID": "blog/project3/index.html#experimental-results",
    "href": "blog/project3/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nlibrary(ggplot2)\n\n\n# Create proportion data\nresponse_rate &lt;- data %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(prop_gave = mean(gave)) %&gt;%\n  mutate(group = ifelse(treatment == 1, \"Treatment\", \"Control\"))\n\n\n# Plot\nggplot(response_rate, aes(x = group, y = prop_gave, fill = group)) +\n  geom_col(width = 0.6, show.legend = FALSE) +\n  labs(\n    title = \"Proportion of Donors Who Gave\",\n    x = \"\",\n    y = \"Proportion\"\n  ) +\n  scale_fill_manual(values = c(\"#4575b4\", \"#d73027\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# T-test (manual)\ntreat_gave &lt;- filter(data, treatment == 1)$gave\ncontrol_gave &lt;- filter(data, treatment == 0)$gave\n\nmean_diff &lt;- mean(treat_gave) - mean(control_gave)\nse &lt;- sqrt(var(treat_gave)/length(treat_gave) + var(control_gave)/length(control_gave))\nt_stat &lt;- mean_diff / se\n\n\n# Show t-statistic\nt_stat\n\n[1] 3.209462\n\n\n\n# OLS regression: gave ~ treatment\nols_model &lt;- lm(gave ~ treatment, data = data)\nsummary(ols_model)\n\n\nCall:\nlm(formula = gave ~ treatment, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02204 -0.02204 -0.02204 -0.01786  0.98214 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.017858   0.001101  16.225  &lt; 2e-16 ***\ntreatment   0.004180   0.001348   3.101  0.00193 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50081 degrees of freedom\nMultiple R-squared:  0.000192,  Adjusted R-squared:  0.0001721 \nF-statistic: 9.618 on 1 and 50081 DF,  p-value: 0.001927\n\n\n\n\n\n\n\n\nWe ran a regression to see whether offering a matching donation increases the likelihood that someone donates. The model tells us that:\nPeople who were offered a match were more likely to donate than those who weren’t. This difference, while small, is statistically significant — meaning it’s unlikely to have happened by random chance. In plain terms: offering a match nudges more people into action.\nEven though the actual increase in donation probability is modest, it is consistent across a large sample and enough to be detectable with statistical tools. This supports the idea that small behavioral cues — like knowing your gift will be matched — can meaningfully change human behavior.\n\n\n\n\n# Probit model\nprobit_model &lt;- glm(gave ~ treatment, data = data, family = binomial(link = \"probit\"))\nsummary(probit_model)\n\n\nCall:\nglm(formula = gave ~ treatment, family = binomial(link = \"probit\"), \n    data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.10014    0.02332 -90.074  &lt; 2e-16 ***\ntreatment    0.08678    0.02788   3.113  0.00185 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10061  on 50081  degrees of freedom\nAIC: 10065\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\n\n\n\n\nIn the paper, Table 3 Column 1 reports:\nA positive and significant coefficient on treatment (around 0.087), Showing that being offered a match increases the probability of donating, even in a nonlinear probit model.\nMy result: treatment coefficient = 0.087 (rounded), z = 3.11, p &lt; 0.01,\nStatistically significant at the 1% level, Exactly what the authors report.\nEven when we use a more sophisticated statistical model (probit), the result still holds: People who received a matching offer were significantly more likely to donate. This finding confirms that behavioral nudges like match offers can shape real-world decisions, even when the actual incentive is small.\n\n\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Only include treated individuals (match group)\nmatch_data &lt;- filter(data, treatment == 1)\n\n# Subset by match ratio\nr1 &lt;- filter(match_data, ratio == 1)$gave\nr2 &lt;- filter(match_data, ratio == 2)$gave\nr3 &lt;- filter(match_data, ratio == 3)$gave\n\n# 1:1 vs 2:1\nt_stat_r1_r2 &lt;- (mean(r2) - mean(r1)) / sqrt(var(r2)/length(r2) + var(r1)/length(r1))\n\n# 2:1 vs 3:1\nt_stat_r2_r3 &lt;- (mean(r3) - mean(r2)) / sqrt(var(r3)/length(r3) + var(r2)/length(r2))\n\n# Output\nt_stat_r1_r2\n\n[1] 0.965049\n\n\n\n\n\n\n\n\nThis value is well below 1.96, the threshold for statistical significance at the 95% confidence level.So, No, the 2:1 match does not significantly increase the donation rate compared to 1:1.\n\n\n\n\nt_stat_r2_r3\n\n[1] 0.05011581\n\n\nThis is even closer to zero, showing almost no difference between the 2:1 and 3:1 match rates.\n\n# Create dummy for 1:1 match (reference category)\nmatch_data &lt;- match_data %&gt;%\n  mutate(\n    ratio1 = ifelse(ratio == 1, 1, 0),\n    ratio2 = ifelse(ratio == 2, 1, 0),\n    ratio3 = ifelse(ratio == 3, 1, 0)\n  )\n\n# Regression using dummy variables\nmodel_ratios &lt;- lm(gave ~ ratio2 + ratio3, data = match_data)\nsummary(model_ratios)\n\n\nCall:\nlm(formula = gave ~ ratio2 + ratio3, data = match_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.020749   0.001391  14.912   &lt;2e-16 ***\nratio2      0.001884   0.001968   0.958    0.338    \nratio3      0.001984   0.001968   1.008    0.313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n# Alternative: regression using ratio as a factor\nmodel_factor &lt;- lm(gave ~ factor(ratio), data = match_data)\nsummary(model_factor)\n\n\nCall:\nlm(formula = gave ~ factor(ratio), data = match_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    0.020749   0.001391  14.912   &lt;2e-16 ***\nfactor(ratio)2 0.001884   0.001968   0.958    0.338    \nfactor(ratio)3 0.001984   0.001968   1.008    0.313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n\n\n\n\n\n\n\nTo test whether larger match ratios increase the likelihood of donating, I ran a regression where the outcome was whether someone gave (gave), and the key predictors were the match ratio levels: 1:1, 2:1, and 3:1.\nI used two approaches: 1. Dummy variables for ratio2 and ratio3 (with ratio1 as the baseline), 2. A factor variable for match ratio (same result, just different syntax).\nThe base group is those who received a 1:1 match offer. The coefficients are very small (under 0.2 percentage points), and The p-values are well above 0.05, meaning the differences are not statistically significant. People who received a 2:1 or 3:1 match were not more likely to donate than those who received a 1:1 match. The regression confirms that increasing the match ratio doesn’t meaningfully change behavior.\nThese findings support the paper’s conclusion: the presence of a match increases giving, but larger match sizes don’t matter. This insight has practical value for fundraisers: there’s no added benefit to offering a more generous match ratio — just having a match is what counts.\n\n\n\n\n# Subset only the treatment group\nmatch_data &lt;- filter(data, treatment == 1)\n\n# Create readable match ratio labels\nmatch_data &lt;- match_data %&gt;%\n  mutate(ratio_group = case_when(\n    ratio2 == 1 ~ \"2:1\",\n    ratio3 == 1 ~ \"3:1\",\n    TRUE ~ \"1:1\"\n  ))\n\n# Compute response rates\nresponse_rates &lt;- match_data %&gt;%\n  group_by(ratio_group) %&gt;%\n  summarise(response_rate = mean(gave))\n\nresponse_rates\n\n# A tibble: 3 × 2\n  ratio_group response_rate\n  &lt;chr&gt;               &lt;dbl&gt;\n1 1:1                0.0207\n2 2:1                0.0226\n3 3:1                0.0227\n\n\n\n\n\n\n\n\nThe 2:1 match increased giving by 0.19 percentage points over 1:1. The 3:1 match increased it by just 0.01 percentage points over 2:1.\nWhether we look at the raw data or the regression model, we find that increasing the match ratio from 1:1 to 2:1, or from 2:1 to 3:1, produces minimal and statistically insignificant increases in donation rates.\nThis confirms the central message in Karlan & List (2007): “The presence of a match increases giving, but making it more generous doesn’t help.” Fundraisers don’t need to secure a 3:1 match to succeed — just having any match at all is effective.\n\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# T-test\nt.test(amount ~ treatment, data = data)\n\n\n    Welch Two Sample t-test\n\ndata:  amount by treatment\nt = -1.9183, df = 36216, p-value = 0.05509\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.310555423  0.003344493\nsample estimates:\nmean in group 0 mean in group 1 \n      0.8132678       0.9668733 \n\n# OLS regression\nmodel_uncond &lt;- lm(amount ~ treatment, data = data)\nsummary(model_uncond)\n\n\nCall:\nlm(formula = amount ~ treatment, data = data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -0.97  -0.97  -0.97  -0.81 399.03 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.81327    0.06742  12.063   &lt;2e-16 ***\ntreatment    0.15361    0.08256   1.861   0.0628 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.709 on 50081 degrees of freedom\nMultiple R-squared:  6.911e-05, Adjusted R-squared:  4.915e-05 \nF-statistic: 3.461 on 1 and 50081 DF,  p-value: 0.06282\n\n\n\n\n\n\n\n\nThe average donation in the control group was $0.81 and the average in the treatment group was $0.97. The difference of about 15 cents is only marginally significant (just above p = 0.05)\nPeople who received a match offer gave slightly more on average, but the increase is not statistically strong enough to rule out random chance at conventional thresholds. This suggests that most of the effect of the treatment comes from getting more people to donate at all, rather than getting people to donate larger amounts. So, Offering a match works by increasing participation, not by increasing generosity. The regression confirms the direction of the effect is positive, but it’s small and imprecise.\n\n\n\n\n# Filter to donors only\ndonors &lt;- filter(data, gave == 1)\n\n# T-test\nt.test(amount ~ treatment, data = donors)\n\n\n    Welch Two Sample t-test\n\ndata:  amount by treatment\nt = 0.58461, df = 557.46, p-value = 0.559\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -3.937240  7.274027\nsample estimates:\nmean in group 0 mean in group 1 \n       45.54027        43.87188 \n\n# Regression\nmodel_cond &lt;- lm(amount ~ treatment, data = donors)\nsummary(model_cond)\n\n\nCall:\nlm(formula = amount ~ treatment, data = donors)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-43.54 -23.87 -18.87   6.13 356.13 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   45.540      2.423  18.792   &lt;2e-16 ***\ntreatment     -1.668      2.872  -0.581    0.561    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.83 on 1032 degrees of freedom\nMultiple R-squared:  0.0003268, Adjusted R-squared:  -0.0006419 \nF-statistic: 0.3374 on 1 and 1032 DF,  p-value: 0.5615\n\n\n\n\n\n\n\n\nAmong people who actually made a donation, the average gift in the control group was $45.54, while the average in the treatment group was slightly lower at $43.87. The difference of about $1.67 is not statistically significant (p ≈ 0.56), meaning we can’t confidently say this difference is due to the treatment rather than random variation.\nThis suggests that while offering a match encourages more people to give overall, it does not make those who were already inclined to donate give more. In other words, the match boosts participation, not generosity. Because this analysis only includes donors, it doesn’t have a clean causal interpretation—but it supports the broader conclusion that matching works primarily by expanding the donor base, not by increasing donation size.\n\n\n\n\nlibrary(ggplot2)\n\n# Add group label\ndonors &lt;- donors %&gt;%\n  mutate(group = ifelse(treatment == 1, \"Treatment\", \"Control\"))\n\n# Group means for vertical lines\nmeans &lt;- donors %&gt;%\n  group_by(group) %&gt;%\n  summarise(mean_amount = mean(amount))\n\n# Plot\nggplot(donors, aes(x = amount)) +\n  geom_histogram(binwidth = 5, fill = \"#69b3a2\", color = \"white\") +\n  geom_vline(data = means, aes(xintercept = mean_amount), color = \"red\", linetype = \"dashed\", size = 1) +\n  facet_wrap(~group) +\n  labs(\n    title = \"Donation Amounts Among Donors\",\n    x = \"Donation Amount ($)\",\n    y = \"Number of Donors\"\n  ) +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "blog/project3/index.html#simulation-experiment",
    "href": "blog/project3/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nset.seed(123)\n\n# Step 1: Simulate draws\ncontrol_draws &lt;- rbinom(100000, 1, 0.018)   # 100,000 draws from control (p = 0.018)\ntreat_draws   &lt;- rbinom(10000, 1, 0.022)    # 10,000 draws from treatment (p = 0.022)\n\n# Step 2: Take first 10,000 of each for comparison\ncontrol_sample &lt;- control_draws[1:10000]\ntreat_sample   &lt;- treat_draws[1:10000]\n\n# Step 3: Calculate difference vector\ndiff_vector &lt;- treat_sample - control_sample  # element-wise difference\n\n# Step 4: Cumulative average of differences\ncum_avg &lt;- cumsum(diff_vector) / seq_along(diff_vector)\n\n# Step 5: Plot cumulative average\nlibrary(ggplot2)\n\nggplot(data.frame(n = 1:10000, cum_avg = cum_avg), aes(x = n, y = cum_avg)) +\n  geom_line(color = \"#1b9e77\") +\n  geom_hline(yintercept = 0.004, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Law of Large Numbers: Cumulative Average of Differences\",\n    subtitle = \"True difference = 0.004 (shown in red)\",\n    x = \"Number of Simulated Pairs\",\n    y = \"Cumulative Average (Treatment − Control)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis plot shows how the cumulative average of simulated differences in donation rates between the treatment and control groups behaves as we increase the number of simulated pairs.\nEarly in the plot (with few observations), the cumulative average is highly volatile — it swings up and down because small samples are noisy. As more pairs are simulated, the line settles and smooths out, converging toward the true average treatment effect (0.004), marked by the red dashed line.\nBy the time we reach several thousand observations, the cumulative average stays consistently close to 0.004, illustrating the Law of Large Numbers in action. As the number of simulations grows, the cumulative average stabilizes and approaches the true difference in means — exactly what LLN predicts.\n\n\n\n\n\nCentral Limit Theorem\n\nset.seed(123)\n\n# Parameters\np_control &lt;- 0.018\np_treat &lt;- 0.022\nn_sims &lt;- 1000\nsample_sizes &lt;- c(50, 200, 500, 1000)\n\n# Load plotting library\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\n\n# Simulate for each sample size\nsimulate_diffs &lt;- function(n) {\n  replicate(n_sims, {\n    control &lt;- rbinom(n, 1, p_control)\n    treatment &lt;- rbinom(n, 1, p_treat)\n    mean(treatment) - mean(control)\n  })\n}\n\n# Generate data for all sample sizes\nsim_results &lt;- map_dfr(sample_sizes, function(n) {\n  data.frame(\n    diff = simulate_diffs(n),\n    n = paste0(\"n = \", n)\n  )\n})\n\n# Plot histograms\nggplot(sim_results, aes(x = diff)) +\n  geom_histogram(bins = 30, fill = \"#66c2a5\", color = \"black\") +\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\", linewidth = 1.2) +\n  facet_wrap(~n, scales = \"free_y\") +\n  labs(\n    title = \"Sampling Distribution of Differences by Sample Size\",\n    subtitle = \"Red dashed line = no effect (difference = 0)\",\n    x = \"Difference in Proportions (Treatment − Control)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nn = 50: The distribution is wide and irregular, and zero is near the center. This means we can’t reliably detect a treatment effect with such small samples.\nn = 200: The shape becomes more symmetric and normal, but zero is still well within the main bulk, suggesting limited power.\nn = 500: The distribution tightens, and we begin to see a slight shift away from zero, meaning more consistent detection of the small true effect.\nn = 1000: The distribution is narrow and centered near the true effect (~0.004). Now, zero is closer to the tail, indicating we’d likely reject the null in a real hypothesis test.\nThese plots demonstrate that:\nWith small sample sizes, statistical noise overwhelms the signal — it’s hard to detect real effects. As the sample size grows, the distribution of estimated differences narrows and zero moves into the tail, giving us more confidence in detecting true effects. This visualizes why large samples are crucial in experiments, especially when the effect size is small — like in this charitable giving study."
  },
  {
    "objectID": "blog/project2/index.html",
    "href": "blog/project2/index.html",
    "title": "This is Project 2",
    "section": "",
    "text": "I cleaned some data.\n\n\n\nI analyzed the data."
  },
  {
    "objectID": "blog/project2/index.html#section-1-datal",
    "href": "blog/project2/index.html#section-1-datal",
    "title": "This is Project 2",
    "section": "",
    "text": "I cleaned some data."
  },
  {
    "objectID": "blog/project2/index.html#section-2-analysis",
    "href": "blog/project2/index.html#section-2-analysis",
    "title": "This is Project 2",
    "section": "",
    "text": "I analyzed the data."
  }
]