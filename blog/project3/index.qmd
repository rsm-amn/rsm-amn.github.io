---
title: "A Replication of Karlan and List (2007)"
author: "Aman Sharma"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).

_to do: expand on the description of the experiment._

This project seeks to replicate their results.


## Data
```{r}
library(haven)
data <- read_dta("/Users/amansharma/amn_website/amn_website/blog/project3/karlan_list_2007.dta")
```

### Description
```{r}
## Load libraries
library(haven)
library(dplyr)
library(ggplot2)
library(skimr)
# Read the data
data <- read_dta("karlan_list_2007.dta")

# View structure of the dataset
str(data)

# Quick summary of numeric and categorical variables
skim(data)


data %>%
  group_by(treatment) %>%
  summarise(
    response_rate = mean(gave),
    avg_donation = mean(amount),
    n = n()
  )

```
:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::

### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

```{r}

library(dplyr)
library(broom)

# Split data
treat <- filter(data, treatment == 1)
control <- filter(data, treatment == 0)
```
```{r}
# Variable 1: Months since last donation (mrm2)
mean_diff_mrm2 <- mean(treat$mrm2, na.rm = TRUE) - mean(control$mrm2, na.rm = TRUE)
se_mrm2 <- sqrt(var(treat$mrm2, na.rm = TRUE)/nrow(treat) +
                var(control$mrm2, na.rm = TRUE)/nrow(control))
t_stat_mrm2 <- mean_diff_mrm2 / se_mrm2

```
```{r}
# Variable 2: Highest previous contribution (hpa)
mean_diff_hpa <- mean(treat$hpa, na.rm = TRUE) - mean(control$hpa, na.rm = TRUE)
se_hpa <- sqrt(var(treat$hpa, na.rm = TRUE)/nrow(treat) +
               var(control$hpa, na.rm = TRUE)/nrow(control))
t_stat_hpa <- mean_diff_hpa / se_hpa

```
```{r}
# Display t-stats
t_stat_mrm2
t_stat_hpa
```
```{r}
# Regress mrm2 (months since last donation) on treatment
model_mrm2 <- lm(mrm2 ~ treatment, data = data)
tidy(model_mrm2)
```
```{r}
# Regress hpa (highest previous contribution) on treatment
model_hpa <- lm(hpa ~ treatment, data = data)
tidy(model_hpa)
```

Table 1 in Karlan & List (2007) reports summary statistics by treatment and control to:
1. Show that randomization succeeded — groups look balanced.
2. Build confidence that observed outcome differences are due to the treatment, not confounders.

This is standard in field experiments and pre-registered RCTs — a "sanity check" for the experiment’s internal validity.

## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

```{r}
library(ggplot2)
```
```{r}
# Create proportion data
response_rate <- data %>%
  group_by(treatment) %>%
  summarise(prop_gave = mean(gave)) %>%
  mutate(group = ifelse(treatment == 1, "Treatment", "Control"))
```
```{r}
# Plot
ggplot(response_rate, aes(x = group, y = prop_gave, fill = group)) +
  geom_col(width = 0.6, show.legend = FALSE) +
  labs(
    title = "Proportion of Donors Who Gave",
    x = "",
    y = "Proportion"
  ) +
  scale_fill_manual(values = c("#4575b4", "#d73027")) +
  theme_minimal()
```
```{r}

# T-test (manual)
treat_gave <- filter(data, treatment == 1)$gave
control_gave <- filter(data, treatment == 0)$gave

mean_diff <- mean(treat_gave) - mean(control_gave)
se <- sqrt(var(treat_gave)/length(treat_gave) + var(control_gave)/length(control_gave))
t_stat <- mean_diff / se
```
```{r}
# Show t-statistic
t_stat
```
```{r}
# OLS regression: gave ~ treatment
ols_model <- lm(gave ~ treatment, data = data)
summary(ols_model)
```
We ran a regression to see whether offering a matching donation increases the likelihood that someone donates. The model tells us that:

People who were offered a match were more likely to donate than those who weren’t. This difference, while small, is statistically significant — meaning it’s unlikely to have happened by random chance. In plain terms: offering a match nudges more people into action.

Even though the actual increase in donation probability is modest, it is consistent across a large sample and enough to be detectable with statistical tools. This supports the idea that small behavioral cues — like knowing your gift will be matched — can meaningfully change human behavior.

```{r}
# Probit model
probit_model <- glm(gave ~ treatment, data = data, family = binomial(link = "probit"))
summary(probit_model)
```
In the paper, Table 3 Column 1 reports:

A positive and significant coefficient on treatment (around 0.087), Showing that being offered a match increases the probability of donating, even in a nonlinear probit model.

My result:
treatment coefficient = 0.087 (rounded),
z = 3.11, p < 0.01,

Statistically significant at the 1% level, Exactly what the authors report.

Even when we use a more sophisticated statistical model (probit), the result still holds:
People who received a matching offer were significantly more likely to donate. This finding confirms that behavioral nudges like match offers can shape real-world decisions, even when the actual incentive is small.

### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

```{r}

# Only include treated individuals (match group)
match_data <- filter(data, treatment == 1)

# Subset by match ratio
r1 <- filter(match_data, ratio == 1)$gave
r2 <- filter(match_data, ratio == 2)$gave
r3 <- filter(match_data, ratio == 3)$gave

# 1:1 vs 2:1
t_stat_r1_r2 <- (mean(r2) - mean(r1)) / sqrt(var(r2)/length(r2) + var(r1)/length(r1))

# 2:1 vs 3:1
t_stat_r2_r3 <- (mean(r3) - mean(r2)) / sqrt(var(r3)/length(r3) + var(r2)/length(r2))

# Output
t_stat_r1_r2
```

This value is well below 1.96, the threshold for statistical significance at the 95% confidence level.So, No, the 2:1 match does not significantly increase the donation rate compared to 1:1.

```{r}

t_stat_r2_r3

```
This is even closer to zero, showing almost no difference between the 2:1 and 3:1 match rates.

```{r}

# Create dummy for 1:1 match (reference category)
match_data <- match_data %>%
  mutate(
    ratio1 = ifelse(ratio == 1, 1, 0),
    ratio2 = ifelse(ratio == 2, 1, 0),
    ratio3 = ifelse(ratio == 3, 1, 0)
  )

# Regression using dummy variables
model_ratios <- lm(gave ~ ratio2 + ratio3, data = match_data)
summary(model_ratios)

# Alternative: regression using ratio as a factor
model_factor <- lm(gave ~ factor(ratio), data = match_data)
summary(model_factor)
```
To test whether larger match ratios increase the likelihood of donating, I ran a regression where the outcome was whether someone gave (gave), and the key predictors were the match ratio levels: 1:1, 2:1, and 3:1.

I used two approaches:
1. Dummy variables for ratio2 and ratio3 (with ratio1 as the baseline),
2. A factor variable for match ratio (same result, just different syntax).

The base group is those who received a 1:1 match offer. The coefficients are very small (under 0.2 percentage points), and The p-values are well above 0.05, meaning the differences are not statistically significant.

People who received a 2:1 or 3:1 match were not more likely to donate than those who received a 1:1 match. The regression confirms that increasing the match ratio doesn’t meaningfully change behavior.

These findings support the paper’s conclusion: the presence of a match increases giving, but larger match sizes don’t matter.

This insight has practical value for fundraisers: there’s no added benefit to offering a more generous match ratio — just having a match is what counts.

```{r}

# Subset only the treatment group
match_data <- filter(data, treatment == 1)

# Create readable match ratio labels
match_data <- match_data %>%
  mutate(ratio_group = case_when(
    ratio2 == 1 ~ "2:1",
    ratio3 == 1 ~ "3:1",
    TRUE ~ "1:1"
  ))

# Compute response rates
response_rates <- match_data %>%
  group_by(ratio_group) %>%
  summarise(response_rate = mean(gave))

response_rates
```

The 2:1 match increased giving by 0.19 percentage points over 1:1.
The 3:1 match increased it by just 0.01 percentage points over 2:1.

Whether we look at the raw data or the regression model, we find that increasing the match ratio from 1:1 to 2:1, or from 2:1 to 3:1, produces minimal and statistically insignificant increases in donation rates.

This confirms the central message in Karlan & List (2007):

“The presence of a match increases giving, but making it more generous doesn’t help.” Fundraisers don’t need to secure a 3:1 match to succeed — just having any match at all is effective.

### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.

```{r}
# T-test
t.test(amount ~ treatment, data = data)

# OLS regression
model_uncond <- lm(amount ~ treatment, data = data)
summary(model_uncond)
```
The average donation in the control group was $0.81
The average in the treatment group was $0.97

The difference of about 15 cents is only marginally significant (just above p = 0.05)

People who received a match offer gave slightly more on average, but the increase is not statistically strong enough to rule out random chance at conventional thresholds. This suggests that most of the effect of the treatment comes from getting more people to donate at all, rather than getting people to donate larger amounts.

So, Offering a match works by increasing participation, not by increasing generosity. The regression confirms the direction of the effect is positive, but it’s small and imprecise.

```{r}
# Filter to donors only
donors <- filter(data, gave == 1)

# T-test
t.test(amount ~ treatment, data = donors)

# Regression
model_cond <- lm(amount ~ treatment, data = donors)
summary(model_cond)
```
The average donation in the control group was $0.81
The average in the treatment group was $0.97

The difference of about 15 cents is only marginally significant (just above p = 0.05)

People who received a match offer gave slightly more on average, but the increase is not statistically strong enough to rule out random chance at conventional thresholds. This suggests that most of the effect of the treatment comes from getting more people to donate at all, rather than getting people to donate larger amounts.

So, Offering a match works by increasing participation, not by increasing generosity. The regression confirms the direction of the effect is positive, but it’s small and imprecise.

```{r}
library(ggplot2)

# Add group label
donors <- donors %>%
  mutate(group = ifelse(treatment == 1, "Treatment", "Control"))

# Group means for vertical lines
means <- donors %>%
  group_by(group) %>%
  summarise(mean_amount = mean(amount))

# Plot
ggplot(donors, aes(x = amount)) +
  geom_histogram(binwidth = 5, fill = "#69b3a2", color = "white") +
  geom_vline(data = means, aes(xintercept = mean_amount), color = "red", linetype = "dashed", size = 1) +
  facet_wrap(~group) +
  labs(
    title = "Donation Amounts Among Donors",
    x = "Donation Amount ($)",
    y = "Number of Donors"
  ) +
  theme_minimal()

```

## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers
```{r}

set.seed(123)

# Step 1: Simulate draws
control_draws <- rbinom(100000, 1, 0.018)   # 100,000 draws from control (p = 0.018)
treat_draws   <- rbinom(10000, 1, 0.022)    # 10,000 draws from treatment (p = 0.022)

# Step 2: Take first 10,000 of each for comparison
control_sample <- control_draws[1:10000]
treat_sample   <- treat_draws[1:10000]

# Step 3: Calculate difference vector
diff_vector <- treat_sample - control_sample  # element-wise difference

# Step 4: Cumulative average of differences
cum_avg <- cumsum(diff_vector) / seq_along(diff_vector)

# Step 5: Plot cumulative average
library(ggplot2)

ggplot(data.frame(n = 1:10000, cum_avg = cum_avg), aes(x = n, y = cum_avg)) +
  geom_line(color = "#1b9e77") +
  geom_hline(yintercept = 0.004, linetype = "dashed", color = "red") +
  labs(
    title = "Law of Large Numbers: Cumulative Average of Differences",
    subtitle = "True difference = 0.004 (shown in red)",
    x = "Number of Simulated Pairs",
    y = "Cumulative Average (Treatment − Control)"
  ) +
  theme_minimal()

```
This plot shows how the cumulative average of simulated differences in donation rates between the treatment and control groups behaves as we increase the number of simulated pairs.

Early in the plot (with few observations), the cumulative average is highly volatile — it swings up and down because small samples are noisy. As more pairs are simulated, the line settles and smooths out, converging toward the true average treatment effect (0.004), marked by the red dashed line.

By the time we reach several thousand observations, the cumulative average stays consistently close to 0.004, illustrating the Law of Large Numbers in action. As the number of simulations grows, the cumulative average stabilizes and approaches the true difference in means — exactly what LLN predicts.

### Central Limit Theorem
```{r}

set.seed(123)

# Parameters
p_control <- 0.018
p_treat <- 0.022
n_sims <- 1000
sample_sizes <- c(50, 200, 500, 1000)

# Load plotting library
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)

# Simulate for each sample size
simulate_diffs <- function(n) {
  replicate(n_sims, {
    control <- rbinom(n, 1, p_control)
    treatment <- rbinom(n, 1, p_treat)
    mean(treatment) - mean(control)
  })
}

# Generate data for all sample sizes
sim_results <- map_dfr(sample_sizes, function(n) {
  data.frame(
    diff = simulate_diffs(n),
    n = paste0("n = ", n)
  )
})

# Plot histograms
ggplot(sim_results, aes(x = diff)) +
  geom_histogram(bins = 30, fill = "#66c2a5", color = "black") +
  geom_vline(xintercept = 0, color = "red", linetype = "dashed", linewidth = 1.2) +
  facet_wrap(~n, scales = "free_y") +
  labs(
    title = "Sampling Distribution of Differences by Sample Size",
    subtitle = "Red dashed line = no effect (difference = 0)",
    x = "Difference in Proportions (Treatment − Control)",
    y = "Count"
  ) +
  theme_minimal()

```
n = 50: The distribution is wide and irregular, and zero is near the center. This means we can't reliably detect a treatment effect with such small samples.

n = 200: The shape becomes more symmetric and normal, but zero is still well within the main bulk, suggesting limited power.

n = 500: The distribution tightens, and we begin to see a slight shift away from zero, meaning more consistent detection of the small true effect.

n = 1000: The distribution is narrow and centered near the true effect (~0.004). Now, zero is closer to the tail, indicating we’d likely reject the null in a real hypothesis test.

These plots demonstrate that:
With small sample sizes, statistical noise overwhelms the signal — it's hard to detect real effects.
As the sample size grows, the distribution of estimated differences narrows and zero moves into the tail, giving us more confidence in detecting true effects. This visualizes why large samples are crucial in experiments, especially when the effect size is small — like in this charitable giving study.